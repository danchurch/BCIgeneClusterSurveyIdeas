## let's take a look at the BCI tree census data

## let's see if we can a geopandas df going...

import pandas as pd
import shapely as sh
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import rasterio as rs
import rasterio.plot as rsPlot
import Bio
from Bio import Entrez
plt.ion()

## think this is a tsv:

censusPath = '/home/daniel/Documents/job_apps/panama/data/treeCensusData/PlotDataReport10-13-2020_1762275259.txt'
BCItrees = pd.read_csv(censusPath, sep='\t')

BCItrees.head()

(BCItrees.Census == 7).all()

## spatial data is in there, can we make that into a shapely points obj?

BCIgdf = gpd.GeoDataFrame(
    BCItrees, geometry=gpd.points_from_xy(BCItrees.PX, BCItrees.PY))

## how does that look?
BCIgdf.head()
 
## great. Now what do we want?

## we basically want a rank abundance curve...

## we need to group by species, sum, and rank

aa = BCIgdf.groupby(BCIgdf['Latin'])
aa.agg(len) ## works. but a better way?
aa.agg(np.size) ## also works. same, basically
abundances = aa.agg(np.size)['Census'].copy() ## not that clever, but works.
abundances.sort_values(ascending=False, inplace=True)


## that worked...? sanity checks
## there should be 10631 lines with Alseis blackiana
(BCItrees.Latin == 'Alseis blackiana').sum() ## yup
## there should be 10631 lines with Alseis blackiana
abundances.tail()
## Pterocarpus officinalis should be observed only once
(BCItrees.Latin == 'Pterocarpus officinalis').sum() ## yup
np.sum(abundances)
BCIgdf.shape 

## rank abundence plot:

plt.close('all')
xs = np.arange(0,len(abundances))
plt.bar(xs, abundances)
## give names:
plt.bar(xs, abundances)
plt.gca().set_xticks(xs)
plt.gca().set_xticklabels(abundances.index, rotation=90)
plt.gca().set_xlim(-0.5,10.5)
plt.tight_layout()

## zoom in
plt.gca().set_xlim(0,10)




##### generating map ##############

## can we read in the nice hillshade tiff of the island?

tifPath = '/home/daniel/Documents/job_apps/panama/data/GIS/BCI_ColoredShaded_Relief/BCI_ColoredShaded_Relief.tif'
twfPath = '/home/daniel/Documents/job_apps/panama/data/GIS/BCI_ColoredShaded_Relief/BCI_ColoredShaded_Relief.tif'
BCIrast = rs.open(tifPath)

aa = BCIrast.read()

help(rs.open)

rsPlot.show(BCIrast)
## that didn't work...

plt.imshow(BCIrast)
## that either 


BCIrast = rs.open(tifPath, GEOREF_SOURCES='INTERNAL' )


###################
## not working. Some folks are saying try gdal, in BASH:
gdal_translate -of GTiff BCI_ColoredShaded_Relief.tif BCI_georeff.tiff
## that worked, fixed the above.
###################

tifPath = '/home/daniel/Documents/job_apps/panama/data/GIS/BCI_ColoredShaded_Relief/BCI_georeff.tiff'
BCIrast = rs.open(tifPath)
rsPlot.show(BCIrast)

## that works. 
## now can we add the points of a tree that we are interested in?

abundances.head()

## I like rubiaceae, so...

aa = BCIgdf.groupby(BCIgdf['Latin'])
faramea = aa.get_group('Faramea occidentalis')

faramea.shape

plt.close('all')

fig, ax = plt.subplots(1,1)

tifPath = '/home/daniel/Documents/job_apps/panama/data/GIS/BCI_ColoredShaded_Relief/BCI_georeff.tiff'
BCIrast = rs.open(tifPath)

ax=plt.gca()

rsPlot.show(BCIrast)

rsPlot.show(BCIrast)
faramea.plot(color='red', ax=ax)

## oops, that's not gonna work until figure out where the plot is, UTM-wise
## we have this geojson:

fig, ax = plt.subplots(1,1)

BCI2020path='/home/daniel/Documents/job_apps/panama/data/GIS/Barro_Colorado_Island_20mx20m_Quadrants_-_Feature_Layer.geojson'
BCI2020 = gpd.read_file(BCI2020path)

BCI2020.crs
## this is in lat/long 
## reproject:
## epsg code for 17n is 32617

BCI2020.to_crs("EPSG:32617", inplace=True)

rsPlot.show(BCIrast)
ax = plt.gca()
BCI2020.plot(ax=ax)

## so how can we use this to plot our points?

## we have this point from the website:
## Latitude: 9.154300000000 Longitude: -79.846100000000 
## is this the origin of our plot?

origLL = sh.geometry.Point(-79.8461,9.1543)
d = {'number':['zoop'], 'geometry':[origLL]}
origDF = gpd.GeoDataFrame( d, crs="epsg:4326" )
origDF.to_crs("EPSG:32617", inplace=True)

plt.close('all')

BCI2020.plot()
ax=plt.gca()
origDF.plot(ax=ax)

## works. nope, that is not the origin, unless there are projection
## issues here. 

## anyway, this does not have to be perfect. Let's start by guessing the 
## origin from the quadrant graphic we have:

xa, ya = 625774, 1.01178*10**6
## now can we convert our faramea points with this?
faramea.set_geometry(gpd.points_from_xy(faramea.PX + xa, faramea.PY + ya), inplace=True)

faramea.plot()

## start over

import pandas as pd
import shapely as sh
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import rasterio as rs
import rasterio.plot as rsPlot
import Bio.Seq 
import os, re, copy
from matplotlib.patches import Rectangle as rect
from Bio.Blast import NCBIWWW
from Bio import Entrez
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.Seq import Seq
from Bio.Align.Applications import MuscleCommandline
Entrez.email = "danchurchthomas@gmail.com"
plt.ion()

## get data
tifPath = '/home/daniel/Documents/job_apps/panama/data/GIS/BCI_ColoredShaded_Relief/BCI_georeff.tiff'
BCIrast = rs.open(tifPath)
BCI2020path='/home/daniel/Documents/job_apps/panama/data/GIS/Barro_Colorado_Island_20mx20m_Quadrants_-_Feature_Layer.geojson'
BCI2020 = gpd.read_file(BCI2020path)
BCI2020.to_crs("EPSG:32617", inplace=True)
censusPath = '/home/daniel/Documents/job_apps/panama/data/treeCensusData/PlotDataReport10-13-2020_1762275259.txt'
BCItrees = pd.read_csv(censusPath, sep='\t')
BCIgdf = gpd.GeoDataFrame(
    BCItrees, geometry=gpd.points_from_xy(BCItrees.PX, BCItrees.PY))
streamPath = '/home/daniel/Documents/job_apps/panama/data/GIS/BCI_streams.geojson'
BCIstreams = gpd.read_file(streamPath)
## sample grid
xa, ya = 625774, 1.01178*10**6
sampleX, sampleY = np.meshgrid([ i*100+xa for i in range(1,10) ],
                                [ i*100+ya for i in range(1,5) ])


## this paper has publically available transcriptomic data for six species. 
https://doi.org/10.1111/mec.13999
## these species have been studied quite a bit...maybe that will strengthen the case

## what are they?

Beilschmiedia pendula

Virola surinamensis 
Brosimum alicastrum 
Eugenia nesiotica 
Lacmellea panamensis 
Dipteryx oleifera 

"Eugenia nesiotica"

## can we find these?

## make a function:


def showSpMap(sp, colr):
    plt.close('all')
    aa = BCIgdf.groupby(BCIgdf['Latin'])
    spDF = aa.get_group(sp).copy()
    xa, ya = 625774, 1.01178*10**6
    spDF.set_geometry(gpd.points_from_xy(spDF.PX + xa, spDF.PY + ya), inplace=True)
    rsPlot.show(BCIrast)
    ax = plt.gca()
    BCIstreams.plot(ax=ax, color="blue")
    spDF.plot(ax=ax, color=colr, zorder=3)
    ax.plot(sampleX, sampleY, 
                marker='s',
                markersize=10,
                markeredgewidth=2,
                markeredgecolor='red',
                linestyle='none',
                fillstyle='none',
                color='black',
                zorder=4,
                #markerfacecolor='black',
                )
    ax.set_xlim(spDF.geometry.x.min()-50,spDF.geometry.x.max()+50)
    ax.set_ylim(spDF.geometry.y.min()-50,spDF.geometry.y.max()+50)
    ax.vlines(x=[xa,xa+1000], ymin=ya, ymax=ya+500)
    ax.hlines(xmin=xa, xmax=xa+1000, y=[ya, ya+500])
    #plt.gcf().suptitle(sp)
    plt.tight_layout()
    return(ax)

sp = "Eugenia nesiotica"
colr = 'green'
aa = showSpMap(sp, colr)



## how do we get our sampling scheme on there?

## the thought is to do a 4 x 9 matrix. Corner would be (xa+100, ya+100), 
## then every 100m in each direction:

list(range(1,10))


sampleX, sampleY = np.meshgrid([ i*100+xa for i in range(1,10) ],
                                [ i*100+ya for i in range(1,5) ])
plt.scatter(xx,yy, 
            color="black",
            marker="^",
)

xx, yy = np.meshgrid(sampleX, sampleY, sparse=True)

gpd.points_from_xy(sampleX, sampleY)

xsample = xa + 



plt.gca()


aa = gpd.points_from_xy(x=[xa, xa+1000, xa+1000, xa], y=[ya, ya, ya+1000, ya+1000])

plt.gca().add_patch(bb)


aa = [
"Beilschmiedia pendula",
"Brosimum alicastrum",
"Dipteryx oleifera",
"Eugenia nesiotica",
"Lacmellea panamensis",
"Virola surinamensis", 
]


plt.close('all')

showSpMap(aa[0], 'blue')

showSpMap(aa[1], 'green')

showSpMap(aa[2], 'red')

showSpMap(aa[3], 'black')

showSpMap(aa[4], 'brown')

showSpMap("Eugenia nesiotica", 'black')

## huh. I think any of these will do...one of them was not covered ?
## these were the ones covered by the Mangan et al 2010 study:

Brosimum alicastrum
Beilschmiedia pendula
Eugenia nesiotica
Lacmellea panamensis
Tetragastris panamensis
Virola surinamensis

## looks like dipteryx is not here, instead we have Tetragastris..

## so our options look like this:

aa = [
"Beilschmiedia pendula",
"Brosimum alicastrum",
"Eugenia nesiotica",
"Lacmellea panamensis",
"Virola surinamensis", 
]

plt.close('all')

showSpMap(aa[0], 'blue')

showSpMap(aa[1], 'green')

showSpMap(aa[2], 'red')

showSpMap(aa[3], 'black')

showSpMap(aa[4], 'brown')

## any of these have genomes?
## Eugenia has one congeneric, E. uniflora. I think this is the brazilian cherry 
## says there is a genome, but its only 3mb, can't be right. 
## oh, there it is: 0.03x coverage. That's like zero coverage, but not  quite. 

## okay, so stay with Eugenia for the moment...

## what does a map for this look like?


showSpMap("Eugenia nesiotica", 'black')

## we want a bounding box, and a sampling grid. 

## bounding box:


#########################################################################

## work back a little...how long are these primers?

## we need to know this, to see if illumina sequencing is possible with them...

## then we can decide how many samples we need to achieve a mininum sequencing 
## depth...


## okay, so how do we get some sample NRPS and PKS ? 

## for the NRPS enzyme, they use 
A3F (5′-GCSTACSYSATSTACACSTCSGG)
A7R (5′-SASGTCVCCSGTSCGGTA) 
## from (Ayuso-Sacido and Genilloud, 2005)

## and for PKS they use:
KS (5′-GCIATGGAYCCICARCARMGIVT) 
degKS2R.i (5′-GTICCIGTICCRTGISCYTCIAC)
## from (Schirmer et al., 2005), sponge paper.

## the Ayuso-Sacido paper has PKS type I primers, wonder why they didn't use these?
## dunno. let's just follow their lead for the moment...

## what next...we need some NRPS sequences to look at...

## how can we get these? Seems like a job for genbank and biopython

########## get some data from genbank ########

## for starters, let's check ~100 sequences of NRPS adenylation domain
## and see how these primers behave?

Entrez.email = "danchurchthomas@gmail.com"

## what do we need here? We need a set of NRPS to play with. How do we get this?
allNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase adenylation domain", 
#    retmax=7000,
    idtype="acc",
)
allNRPSrecord = Entrez.read(allNRPShandle)
allNRPSrecord['Count'] ## 6607
allNRPSrecord['IdList']


## how can we subset to just fungi?
justFungiNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase adenylation domain AND fungi [ORGN]", 
    idtype="acc",
    retmax=50,
)
justFungiNRPSrecord = Entrez.read(justFungiNRPShandle)
justFungiNRPSrecord['Count'] ## far fewer, 54

justFungiNRPSrecord['IdList'] 

justFungiNRPSrecord


## okay, now bacteria:
justBacteriaNRPShandle = Entrez.esearch(db='nucleotide',
    term="non-ribosomal peptide synthetase adenylation domain AND Bacteria [ORGN]", 
    idtype="acc",
    retmax=50,
)
justBacteriaNRPSrecord = Entrez.read(justBacteriaNRPShandle)
justBacteriaNRPSrecord['Count'] ## lots, 6544
justBacteriaNRPSrecord['IdList']

## what is the difference here between nucleotide and gene?
justFungiNRPShandle = Entrez.esearch(db="gene", 
    term="non-ribosomal peptide synthetase adenylation domain AND fungi [ORGN]", 
    idtype="acc",
    retmax=100,
)
justFungiNRPSrecord = Entrez.read(justFungiNRPShandle)
justFungiNRPSrecord['Count'] ## huh, that's a lot more...538
justFungiNRPSrecord['IdList'] ## these are not acession numbers...

justBacteriaNRPShandle = Entrez.esearch(db="gene", 
    term="non-ribosomal peptide synthetase adenylation domain AND bacteria [ORGN]", 
    idtype="acc",
    retmax=100,
)
justBacteriaNRPSrecord = Entrez.read(justBacteriaNRPShandle)

justBacteriaNRPSrecord['Count'] ## dramatically less than the nucleotide database 1175

## for kicks, look at plants?
justPlantsNRPShandle = Entrez.esearch(db="gene", 
    term="(non-ribosomal peptide synthetase adenylation domain) AND green plants[porgn:__txid33090]", 
    idtype="acc",
    retmax=100,
)
justPlantsNRPSrecord = Entrez.read(justPlantsNRPShandle)
justPlantsNRPSrecord['Count'] ## just 3


## 'gene' may be just genbank results, the hopefully well-curated gene sequences,
## excluding the annotated chromosomes with automated matches etc. 
## might be better to use...let's keep them...
## we might consider randomizing our sample a bit. But I assumed there is a bit
## of quality control built into the search algorithmns, in that the first 
## matches are more likely to actually be NRPSes than later matches?
## so keep these top 100 matches of each for now...

## these can be downloaded from genbank?

## for one record:
handle = Entrez.efetch(db="gene", id="EU490707", rettype="gb", retmode="fasta")

help(Entrez.esearch)
`
help(Entrez.efetch)

## says ids can be comma separated lists, can these be literal lists in python?

aa = justPlantsNRPSrecord['IdList'][0:3]

aa = justFungiNRPSrecord['IdList'][0:3]

handle = Entrez.efetch(db="gene", id=aa, rettype="gb", retmode="fasta")

handle = Entrez.efetch(db="gene", id=aa, rettype="gb", retmode="text")

print(handle.read())

## this is working but not returning sequence data. Also, many don't seem to 
## be NRPSes, even fungal. Think we need to use the nucleotide db to get this?
## not sure if these IDs I have are unique

bb = justPlantsNRPSrecord['IdList'][0]

handle = Entrez.efetch(db="nucleotide", id=bb, rettype="gb", retmode="text")
## is this the same gene as?
handle2 = Entrez.efetch(db="gene", id=bb, rettype="gb", retmode="text")
## nope. 
## I think we need accession numbers

## for one record:

justFungiNRPShandle = Entrez.esearch(db="gene", 
    term="non-ribosomal peptide synthetase adenylation domain AND fungi [ORGN]", 
    idtype="acc",
    retmax=10,
    retmode='text',
)

justFungiNRPSrecord = Entrez.read(justFungiNRPShandle)

justFungiNRPSrecord

print(handle2.read())

## a classic efetch goes like this:
handle = Entrez.efetch(db="nucleotide", id="EU490707", rettype="gb", retmode="text")

## you start with an accession number. And dammit, esearch doesn't seem to return 
## accession numbers. 
## and NCBI is dropping the "GI" number system, which is what esearch returns. 
## as usual, the API for NCBI is a mess.  

## this is not going well...

## okay, so maybe we can hope that they haven't totally phased out the 
## GI numbers, and pipe our esearch results into an efetch  

## or we can use the nucleotide results...:

allNRPSrecord['IdList']

## how can we download these? I think it would look like this:

aa = Entrez.efetch(db="nucleotide", id=allNRPSrecord['IdList'], rettype="gb", retmode="text")

## but let's wait to do that. Apparently there is a better way, by directly caching and piping
## esearch results to efetch, detailed here:
## http://biopython.org/DIST/docs/tutorial/Tutorial.html#sec%3Aentrez-webenv

## so maybe this could be used for the gene database:
allNRPShandle = Entrez.esearch(db="gene", 
    term="non-ribosomal peptide synthetase adenylation domain", 
    retmax=7000,
    idtype="acc",
    usehistory="y",
)

## gives us the usual info:
allNRPSrecord = Entrez.read(allNRPShandle)
allNRPSrecord['Count'] ## 6607
allNRPSrecord['IdList']

acc_list = allNRPSrecord["IdList"]
count = int(allNRPSrecord["Count"])

count == len(acc_list)

## but also the additional variables:

webenv = allNRPSrecord["WebEnv"]
query_key = allNRPSrecord["QueryKey"]

## try getting a few of these with efetch:

fetch_handle = Entrez.efetch(
    db="gene",
    rettype="fasta",
    retmode="text",
    retmax=10,
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

data = fetch_handle.read()

fetch_handle.close()

with open('allNRPS.txt', 'w') as f:
    f.write(data)

## That's promising. But no sequence data.

## the genes don't seem to return any sequence data
## I guess the gene database is more focused on 
## collating information about the role of the gene
## and the various sequences associated with it,
## genomic, mRNA etc.

## seems like we're back to the nucleotide database here:

## do one of adenylation domains:
allNRPSADhandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase adenylation domain", 
    retmax=7000,
    idtype="acc",
    usehistory="y",
)
allNRPSADrecord = Entrez.read(allNRPSADhandle)
acc_list = allNRPSADrecord["IdList"]
count = int(allNRPSADrecord["Count"])
webenvAD = allNRPSADrecord["WebEnv"]
query_keyAD = allNRPSADrecord["QueryKey"]
fetchAD = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=10,
    webenv=webenvAD,
    query_key=query_keyAD,
    idtype="acc",
)
dataAD = fetchAD.read()
with open("ADfastas.txt", 'w') as f:
    f.write(dataAD)
fetchAD.close()

## that looks good. how different does a less specific NRPS (no AD) 
## search look? 

allNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase", 
    retmax=7000,
    idtype="acc",
    usehistory="y",
)

allNRPSrecord = Entrez.read(allNRPShandle)
acc_list = allNRPSrecord["IdList"]
count = int(allNRPSrecord["Count"])
webenv = allNRPSrecord["WebEnv"]
query_key = allNRPSrecord["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=10,
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("NRPSfastas.txt", 'w') as f:
    f.write(dataNRPS)

fetch.close()


## problem, these don't divide by kingdom, which we will need for the 
## writeup (one for fungi, one for bacteria, one for plants)

## so new plan, get these individually by kingdom:

justFungiNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND fungi [ORGN]", 
    idtype="acc",
    retmax=2500,
)
justFungiNRPSrecord = Entrez.read(justFungiNRPShandle)
justFungiNRPSrecord['Count'] ## 2234 

## bacteria - there are so many, let's take the first 50000
justBactNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND bacteria [ORGN]", 
    idtype="acc",
    retmax=50000,
)
justBactNRPSrecord = Entrez.read(justBactNRPShandle)
justBactNRPSrecord['Count'] ## 143457

justPlantNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND green plants[porgn:__txid33090]", 
    idtype="acc",
    retmax=100,
)
justPlantNRPSrecord = Entrez.read(justPlantNRPShandle)
justPlantNRPSrecord['Count'] ## 55
justPlantNRPSrecord['IdList']
## I'll need these to see if our primers pick up these 
## hopefully they don't 

## are our AD results included in these?

pd.Series(allNRPSADrecord["IdList"]).isin(pd.Series(justBactNRPSrecord['IdList']))
pd.Series(allNRPSADrecord["IdList"]).isin(pd.Series(justBactNRPSrecord['IdList'])).sum()
pd.Series(allNRPSADrecord["IdList"]).isin(pd.Series(justBactNRPSrecord['IdList']))
pd.Series(allNRPSADrecord["IdList"]).isin(pd.Series(justBactNRPSrecord['IdList'])).sum() 
## about a third. makes sense, we downloaded about a third of the bacterial NRPS

pd.Series(allNRPSADrecord["IdList"]).isin(pd.Series(justBactNRPSrecord['IdList'])).any()
pd.Series(allNRPSADrecord["IdList"]).isin(pd.Series(justBactNRPSrecord['IdList'])).all()

allNRPSADrecord["IdList"] 


[ i in justBactNRPSrecord['IdList'] for i in allNRPSADrecord["IdList"] ]

[ i in allNRPSADrecord["IdList"] for i in justBactNRPSrecord['IdList'] ]

justBactNRPSrecord['IdList']

allNRPSADrecord["IdList"] 

## okay, so set up the downloads, one for each group. try the small ones first:

## plants:
justPlantNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND green plants[porgn:__txid33090]", 
    idtype="acc",
    retmax=100,
    usehistory="y",
)

justPlantNRPSrecord = Entrez.read(justPlantNRPShandle)


acc_list = justPlantNRPSrecord["IdList"]
count = int(justPlantNRPSrecord["Count"])
webenv = justPlantNRPSrecord["WebEnv"]
query_key = justPlantNRPSrecord["QueryKey"]

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(acc_list),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("PlantNRPSfastas.txt", 'w') as f:
    f.write(dataNRPS)

fetch.close()

## and that results in a big damn file. just 55 sequences.
## we are not going to be able to do this locally.

## How about we build a small library of 100 sequences of bacteria and fungi each, 
## play around with that?

justBactNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND bacteria [ORGN]", 
    idtype="acc",
    retmax=100,
    usehistory="y",
)

justBactNRPSrecord = Entrez.read(justBactNRPShandle)

webenv = justBactNRPSrecord["WebEnv"]
query_key = justBactNRPSrecord["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(justBactNRPSrecord["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("BactAndFungiNRPSfastas.txt", 'w') as f:
    f.write(dataNRPS)

fetch.close()

justFungiNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND fungi [ORGN]", 
    idtype="acc",
    retmax=100,
    usehistory="y",
)

justFungiNRPSrecord = Entrez.read(justFungiNRPShandle)
webenv = justFungiNRPSrecord["WebEnv"]
query_key = justFungiNRPSrecord["QueryKey"]

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(justFungiNRPSrecord["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()

with open("BactAndFungiNRPSfastas.txt", 'a') as f:
    f.write(dataNRPS)

fetch.close()

## make a local blastdb, search that for our primers
## in BASH

makeblastdb -in BactandFungi.fa -parse_seqids -dbtype prot

## look for our primers:

A3F=GCSTACSYSATSTACACSTCSGG
A7R=SASGTCVCCSGTSCGGTA
echo '> A3F' > 'nrpsPrimers.fa' 
echo $A3F >> 'nrpsPrimers.fa'
echo '> A7R' >> 'nrpsPrimers.fa'
echo $A7R >> 'nrpsPrimers.fa'

cat nrpsPrimers.fa

blastn -query nrpsPrimers.fa -subject BactandFungi.fa -evalue 30000

## reverse comp of A3F:
CC.GA.GTGTA.AT...GTA.G

grep GC.TAC...AT.TACAC.TC.GG BactandFungi.fa 

grep GC.TAC...AT.TACAC.TC.GG BactandFungi.fa | wc -l

grep CC.GA.GTGTA.AT...GTA.G BactandFungi.fa 

grep CC.GA.GTGTA.AT...GTA.G BactandFungi.fa  | wc -l

## 30 diff hits...
## they are in there. why doesn't blast pick them up?

## try with the Ns instead of the other ambiguous symbols: 

A3F=GCNTACNNNATNTACACNTCNGG
A7R=SASGTCVCCSGTSCGGTA
echo '> A3F' > 'nrpsPrimers.fa' 
echo $A3F >> 'nrpsPrimers.fa'
echo '> A7R' >> 'nrpsPrimers.fa'
echo $A7R >> 'nrpsPrimers.fa'
blastn -query nrpsPrimers.fa -subject BactandFungi.fa -evalue 30000

## nada...

## let's align them, and look at them. using muscle:

muscle -in BactandFungi.fa -out BactandFungiAligned.fa

## failed. No diagnostics as to why.

## sleep. Then try this with the AD domains...

## awake: Let's get the AD domain info, start an alignment:

## we want the same, ~100 of the bacterial, and as many fungal and
## plant homologues as we can get:

## plants
justPlantNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND green plants[porgn:__txid33090]", 
    idtype="acc",
    retmax=100,
    usehistory="y",
)

record = Entrez.read(justPlantNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("B_F_P_NRPS_AD_fastas.txt", 'w') as f:
    f.write(dataNRPS)
    fetch.close()

## add bacteria
justBactNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND bacteria [ORGN]",
    idtype="acc",
    retmax=100,
    usehistory="y",
)

record = Entrez.read(justBactNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("B_F_P_NRPS_AD_fastas.txt", 'a') as f:
    f.write(dataNRPS)
    fetch.close()

## add fungi
justFungiNRPShandle = Entrez.esearch(db="nucleotide", 
    term="non-ribosomal peptide synthetase AND fungi [ORGN]", 
    idtype="acc",
    retmax=100,
    usehistory="y",
)

record = Entrez.read(justFungiNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("B_F_P_NRPS_AD_fastas.txt", 'a') as f:
    f.write(dataNRPS)
    fetch.close()

## okay..255 sequences...are these easier to align for MUSCLE?

mv B_F_P_NRPS_AD_fastas.txt B_F_P_NRPS_AD.fa

muscle -in B_F_P_NRPS_AD.fa -out BactandFungi_aligned.afa -maxiters 2

## these are all failing. If this continues, reduce the size. 

## keeps "killing" the process, even when I make through an iteration. 

## just to see, what happens with a tiny dataset?

## first ten reads of this fasta? How to subset in biopython...

ADparse = SeqIO.parse("B_F_P_NRPS_AD.fa", "fasta")

AdparseL = list(ADparse)

del(AdparseL)

## first we'll see if we just need to reduce the size of the alignment:

with open ('smallerFasta4Alignment.fa', "w") as f:
    SeqIO.write(AdparseL[0:101], f, "fasta")

## I think this excludes the fungi? so probably also makes the alignment easier


## try again with alignment

muscle -in smallerFasta4Alignment.fa  -out BactandFungi_aligned.afa -maxiters 2

## while that is running, I think a better approach here is generate alignments 
## for each of the three groups, fungi, plants, and bacteria. 

## here we go again...

## fungi
justFungiNRPShandle = Entrez.esearch(db="nucleotide", 
    term="(non-ribosomal peptide synthetase) AND Fungi[Organism] AND biomol_mRNA[Properties]",
    idtype="acc",
    retmax=20,
    usehistory="y",
)

record = Entrez.read(justFungiNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("fungiRPBS_AD.fa", 'w') as f:
    f.write(dataNRPS)
    fetch.close()


## plants

justPlantsNRPShandle = Entrez.esearch(db="nucleotide", 
    term="(non-ribosomal peptide synthetase) AND green plants[porgn:__txid33090] AND biomol_mRNA[Properties]",
    idtype="acc",
    retmax=100,
    usehistory="y",
)

record = Entrez.read(justPlantsNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("plantsRPBS_AD.fa", 'w') as f:
    f.write(dataNRPS)
    fetch.close()

## bacteria. Not sure why, can't get mRNA, so limit length of sequences
justBactNRPShandle = Entrez.esearch(db="nucleotide", 
    #term="(non-ribosomal peptide synthetase) AND bacteria [ORGN] AND biomol_mRNA[Properties]", ## doesn't work, 0 results
    term="(non-ribosomal peptide synthetase) AND bacteria [ORGN] AND (0[SLEN] : 20000[SLEN]))",
    idtype="acc",
    retmax=25,
    usehistory="y",
)

record = Entrez.read(justBactNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("bactRPBS_AD.fa", 'w') as f:
    f.write(dataNRPS)
    fetch.close()

## the plan would be, try these alignments 
## then look for the existing primer sites
## check length and diversity, report

## the reduced dataset also failed, though it made it further, into the alignment 
## stage....

## let's try the fungal only file:

muscle -in fungiRPBS_AD.fa  -out Fungi_AD_aligned.afa #-maxiters 2
## that worked, with 20 sequences...
muscle -in plantsRPBS_AD.fa  -out plantsNRPS_aligned.afa #-maxiters 2

muscle -in bactRPBS_AD.fa  -out bactNRPs_aligned.afa #-maxiters 2

## not sure, my acronyms got mixed up there a bit...

GCNTACNNNATNTACACNTCNGG
CCNGANGTGTANATNNNGTANGC
NANGTCNCCNGTNCGGTA
TACCGNACNGGNGACNTN

A3F=GC.TAC...AT.TACAC.TC.GG
A3Frc=CC.GA.GTGTA.AT...GTA.GC
A7R=.A.GTC.CC.GT.CGGTA
A7Rrc=TACCG.AC.GG.GAC.T.

## check fungi with these
grep $A3F fungiRPBS_AD.fa
grep $A3Frc fungiRPBS_AD.fa
grep $A7R fungiRPBS_AD.fa
grep $A7Rrc fungiRPBS_AD.fa ## hit, 2

grep $A3F bactRPBS_AD.fa
grep $A3Frc bactRPBS_AD.fa ## hit
grep $A7R bactRPBS_AD.fa ## hit
grep $A7Rrc bactRPBS_AD.fa

grep $A3F plantsRPBS_AD.fa
grep $A3Frc plantsRPBS_AD.fa
grep $A7R plantsRPBS_AD.fa
grep $A7Rrc plantsRPBS_AD.fa


## the following was for quickly testing the number of sequences 
## number of seqs:
ns = 5
fa = 0
infiles = ["plantsRPBS_AD.fa", "bactRPBS_AD.fa", "fungiRPBS_AD.fa"]
shortfiles = ["plantsRPBS_AD_short.fa", "bactRPBS_AD_short.fa", "fungiRPBS_AD_short.fa"]
outfiles = ["plantsRPBS_AD.afa", "bactRPBS_AD.afa", "fungiRPBS_AD.afa"]
ADparse = SeqIO.parse(infiles[fa], "fasta")
AdparseL = list(ADparse)
## first we'll see if we just need to reduce the size of the alignment:
with open (shortfiles[fa], "w") as f:
    SeqIO.write(AdparseL[0:ns], f, "fasta")
    #musc = MuscleCommandline(input=shortfiles[fa], out=outfiles[fa])
    ## run the alignment from here? 
    #musc()

## not working to run in biopython...


## looking at this, these are entire large scaffolds, and mRNA all mixed up.
## we want to exclude scaffolds, chromosomes, etc...we need a gene based 
## approach...
########## blasting genbank #######

## fuck all that for the moment... 
## Instead, for the moment, we need to flip this on its head and blast 
## genbank with these primers, see what results. 

## how do we do this?


NCBIWWW.qblast()

## example from the documentation
result_handle = NCBIWWW.qblast("blastn", "nt", "8332116")

## to look for our primers:

## for the NRPS enzyme, they use 

A3F=Bio.Seq.Seq('GCSTACSYSATSTACACSTCSGG')
A7R=Bio.Seq.Seq('SASGTCVCCSGTSCGGTA')

checkNRPSfor = NCBIWWW.qblast("blastn", "nt", A3F)

## yields nothing. probably because of all the ambiguity 
## what if we replace these with N?

## a good page for the ambiguous abbreviations:
## https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp

A3F  =   Bio.Seq.Seq('GCSTACSYSATSTACACSTCSGG')

A3FNNN = Bio.Seq.Seq('GCNTACNNNATNTACACNTCNGG')

checkNRPSfor = NCBIWWW.qblast("blastn", "nt", A3FNNN)

## write this:

with open("A3Fcheck.txt", "w") as out_handle:
    out_handle.write(checkNRPSfor.read())

result_handle.close()

## not working...there are some tips on this page: 

## https://eu.idtdna.com/pages/education/decoded/article/tips-for-using-blast-to-locate-pcr-primers

A3FA7RN = Bio.Seq.Seq('GCNTACNNNATNTACACNTCNGGNNNNNNNNNNNNNNNNNNNNNNNANGTCNCCNGTNCGGTA')

checkNRPSfor = NCBIWWW.qblast("blastn", "nt", A3FA7RN)

## yeah that does nothing...hmmm...

## seems like blasting primer sets just isn't going to work.

## so skip that for now...

## but we have other jobs for genbank. We need a list of useful metabolites to look for, 
## so we can design primers. 
## who am I kidding, I can't design primers. 

## I want to see if our PKS and NRP

## for each, say something interesting, list available literature and 
## accessions/genomes,  find a primer set if available

## for pathogen resistence, we were interested in antimicrobials. 

## antifungals: 
##   echinocandin (NRP lipopeptide, fungal origin)
##   cyclosporing (cyclic NRP, fungal origin)
##   polyenes (polyketide, bacterial origin, maybe also in Fungi?)
##   strobilurins (polyketide, fungal origin, mostly basidios?)

## for drought, antioxidents and osmolytes

## drought & exposure
##   fungal antioxidants:
##    SOD, CAT
##   fungal osmolytes:
##    manitol?

## anti-herbivory
##   ergotamine
##   other alkaloids?

##  

## change of plan - use targeted PCR tests for endophytes, and shotgun metagenomics for 
## epiphytes and soil

## how many samples? Kyle did ten... doesn't seem like much but they still used 
## 21 lanes of hi-seq, jeezus, even at 8 lanes/run that thats 2.5 runs...

## I think we will have to be a bit courser, given our budget. 

## given our budget of $4000, I think we have to stick with metabarcoding + PCR
## but incorporate epiphytes into the samples. Root and leaf washing, pelletizing,
## DNA extraction. Targeted PCR of fungal and bacterial products of interest. 

## need to get draft today. Plan:

## 1 - set up massive searches of plant, fungal, bacterial for primers. Let them 
## run.

## 2 - write draft and budget for advisors

####################################

## 1 - set up searches for primers

## basic idea 
## 1) search and download LOTS of sequences from each category
## 2) set them up as generators
## 3) look for exact matches of our primers in each sequence, tally as you go


## 
## 1 Search and download sequences:

## try method with a few fungal, then expand:
justFungiNRPShandle = Entrez.esearch(db="nucleotide", 
    term="(non-ribosomal peptide synthetase) AND Fungi[Organism] AND biomol_mRNA[Properties]",
    idtype="acc",
    retmax=1000,
    usehistory="y",
)

record = Entrez.read(justFungiNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]
# len(record["IdList"])

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("fungalNRPS.fa", 'w') as f:
    f.write(dataNRPS)
    fetch.close()

## identify our primers:
A3F = Bio.Seq.Seq("CNTACNNNATNTACACNTCNGG")
A7R = Bio.Seq.Seq("ANGTCNCCNGTNCGGTA")
A3Frc = Bio.Seq.Seq("CCNGANGTGTANATNNNGTANG")
A7Rrc = Bio.Seq.Seq("TACCGNACNGGNGACNT")
## or for regex
A3Frg="C.TAC...AT.TACAC.TC.GG"
A7Rrg="A.GTC.CC.GT.CGGTA"
A3Frgrc="CC.GA.GTGTA.AT...GTA.G"
A7Rrgrc="TACCG.AC.GG.GAC.T"

## can we open this directly as a set of seqs?

fungalRecords=list()
matchsNRPS_forwardPrime = list()
matchsNRPS_forwardPrime_RC = list()
matchsNRPS_reversePrime = list()
matchsNRPS_reversePrime_RC = list()
for i in SeqIO.parse("fungalNRPS.fa", "fasta"): 
    ## forward A3F
    forwardPrime = re.search(A3Frg, str(i.seq))
    if forwardPrime: 
        matchsNRPS_forwardPrime.append(forwardPrime.group(0))
        fungalRecords.append(i.description)
    ## forward A3F, reverse comp
    forwardPrime_RC = re.search(A3Frgrc, str(i.seq))
    if forwardPrime_RC: 
        matchsNRPS_forwardPrime_RC.append(forwardPrime.group(0))
        fungalRecords.append(i.description)
    ## reverse A7R primer
    reversePrim = re.search(A7Rrg, str(i.seq))
    if reversePrim: 
        matchsNRPS_reversePrime.append(reversePrim_RC.group(0))
        fungalRecords.append(i.description)
    ## reverse A7R primer, reverse comp 
    reversePrim_RC = re.search(A7Rrgrc, str(i.seq))
    if reversePrim_RC: 
        matchsNRPS_reversePrime_RC.append(reversePrim_RC.group(0))
        fungalRecords.append(i.description)

len(fungalRecords) ## 42
len(set(fungalRecords)) ## 40, so only 2 with both primers?
## =two repeats...so not a lot of complete primer pairs to work with. 
## 42 out of 294 records ~14%, Compare this to bacteria...

len(record["IdList"])

matchsNRPS_forwardPrime
matchsNRPS_forwardPrime_RC
matchsNRPS_reversePrime
matchsNRPS_reversePrime_RC

## so these show some activity in fungi. How extensive, needs more time than I have. 

## do this for bacteria:

justBactNRPShandle = Entrez.esearch(db="nucleotide", 
    #term="(non-ribosomal peptide synthetase) AND bacteria [ORGN] AND biomol_mRNA[Properties]", ## doesn't work, 0 results
    term="(non-ribosomal peptide synthetase) AND bacteria [ORGN] AND (0[SLEN] : 20000[SLEN]))",
    idtype="acc",
    retmax=1000,
    usehistory="y",
)

record = Entrez.read(justBactNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("bactNRPS.fa", 'w') as f:
    f.write(dataNRPS)
    fetch.close()

## now look through these:
bacterialRecords=list()
matchsNRPS_forwardPrime = list()
matchsNRPS_forwardPrime_RC = list()
matchsNRPS_reversePrime = list()
matchsNRPS_reversePrime_RC = list()
## BiodiversityGenomics
for i in SeqIO.parse("bactNRPS.fa", "fasta"): 
    ## forward A3F
    forwardPrime = re.search(A3Frg, str(i.seq))
    if forwardPrime: 
        matchsNRPS_forwardPrime.append(forwardPrime.group(0))
        bacterialRecords.append(i.description)
    ## forward A3F, reverse comp
    forwardPrime_RC = re.search(A3Frgrc, str(i.seq))
    if forwardPrime_RC: 
        matchsNRPS_forwardPrime_RC.append(forwardPrime_RC.group(0))
        bacterialRecords.append(i.description)
    ## reverse A7R primer
    reversePrim = re.search(A7Rrg, str(i.seq))
    if reversePrim: 
        matchsNRPS_reversePrime.append(reversePrim.group(0))
        bacterialRecords.append(i.description)
    ## reverse A7R primer, reverse comp 
    reversePrim_RC = re.search(A7Rrgrc, str(i.seq))
    if reversePrim_RC: 
        matchsNRPS_reversePrime_RC.append(reversePrim_RC.group(0))
        bacterialRecords.append(i.description)


## definitely in there

len(bacterialRecords) ## = 242
len(set(bacterialRecords)) ## 203, 20% of total records. 

matchsNRPS_forwardPrime
matchsNRPS_forwardPrime_RC
matchsNRPS_reversePrime
matchsNRPS_reversePrime_RC

## check plants:

justPlantsNRPShandle = Entrez.esearch(db="nucleotide", 
    term="(non-ribosomal peptide synthetase) AND green plants[porgn:__txid33090] AND biomol_mRNA[Properties]",
    idtype="acc",
    retmax=1000,
    usehistory="y",
)

record = Entrez.read(justPlantsNRPShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()
with open("plantNRPS.fa", 'w') as f:
    f.write(dataNRPS)
    fetch.close()


plantRecords=list()
matchsNRPS_forwardPrime = list()
matchsNRPS_forwardPrime_RC = list()
matchsNRPS_reversePrime = list()
matchsNRPS_reversePrime_RC = list()
for i in SeqIO.parse("plantNRPS.fa", "fasta"): 
    ## forward A3F
    forwardPrime = re.search(A3Frg, str(i.seq))
    if forwardPrime: 
        matchsNRPS_forwardPrime.append(forwardPrime.group(0))
        plantRecords.append(i.description)
    ## forward A3F, reverse comp
    forwardPrime_RC = re.search(A3Frgrc, str(i.seq))
    if forwardPrime_RC: 
        matchsNRPS_forwardPrime_RC.append(forwardPrime_RC.group(0))
        plantRecords.append(i.description)
    ## reverse A7R primer
    reversePrim = re.search(A7Rrg, str(i.seq))
    if reversePrim: 
        matchsNRPS_reversePrime.append(reversePrim_RC.group(0))
        plantRecords.append(i.description)
    ## reverse A7R primer, reverse comp 
    reversePrim_RC = re.search(A7Rrgrc, str(i.seq))
    if reversePrim_RC: 
        matchsNRPS_reversePrime_RC.append(reversePrim_RC.group(0))
        plantRecords.append(i.description)

len(plantRecords) ## 

len(record["IdList"])

matchsNRPS_forwardPrime
matchsNRPS_forwardPrime_RC
matchsNRPS_reversePrime
matchsNRPS_reversePrime_RC

## not picking up anything...
## grep?

grep $A3Frg plantNRPS.fa | wc -l
grep $A7Rrg plantNRPS.fa | wc -l
grep $A3Frgrc plantNRPS.fa | wc -l
grep $A7Rrgrc plantNRPS.fa | wc -l

## no evidence of plant use of these primers. 
## then again, there were only 15 sequences...
## they are probably mis-annotated by automated pipelines.

## okay, what else do we need?

## can we repeat the above, with PKS? 

############################# PKS ############################# 
## now to repeat with PKS.

## I get the impression this is a much larger family of enzymes
## with more activity in plants...

## I also wonder if there is a divide here between bacteria 
## and fungi. the lit says that one pattern is that bacteria
## use multimodular, non-interative PKS-Is, and fungi tend to 
## use a monomodular iterative PKS. But both have KS domains, 
## which are presumably pretty conserved and these primers 
## are pretty darn degenerate...


 the following search on genbank:

(Polyketide Synthase[Protein Name] OR (Polyketide[All Fields] AND Synthase[All Fields])) 
AND iterative[All Fields] AND (type I[Protein Name] OR type[All Fields])


## in the protein database gives us 2,776 records for fungi,
## and only 165 for bacteria. 

## a better search might be:
(((Polyketide Synthase) AND Type I) NOT Type II) NOT Type III 

## how can we get nucleotide info for these, if it is avaiable?

## bacteria
bactPKShandle = Entrez.esearch(db="nucleotide", 
    term="(((Polyketide Synthase) AND Type I) NOT Type II) NOT Type III AND bacteria [ORGN]", 
    idtype="acc",
    retmax=1000,
    usehistory="y",
)
 
record = Entrez.read(bactPKShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()

pksfile='/home/daniel/Documents/job_apps/panama/bigFilesBiodiv/bactPKS.fa'
with open(pksfile, 'w') as f:
    f.write(dataNRPS)
    fetch.close()

## our polyketide primers look like this:

## KS [degKS2F.i (5′-GCIATGGAYCCICARCARMGIVT)
## degKS2R.i (5′-GTICCIGTICCRTGISCYTCIAC)

## so for general purpose biopython manipulation
## sub out the non-GCAT bases:

KS2Fraw = "GCIATGGAYCCICARCARMGIVT"
KS2F = re.sub('[^GCAT]',".", KS2Fraw)
KS2Fseq = Bio.Seq.Seq(KS2F) 
KS2Fseq_RC = KS2Fseq.reverse_complement()
KS2F_RC = str(KS2Fseq_RC)
KS2Rraw = 'GTICCIGTICCRTGISCYTCIAC'
KS2R = re.sub('[^GCAT]',".", KS2Rraw)
KS2Rseq = Bio.Seq.Seq(KS2R) 
KS2Rseq_RC = KS2Rseq.reverse_complement()
KS2R_RC = str(KS2Rseq_RC)

## can we now peruse our bacterial PKS records with this?

PKS_for = list()
PKS_for_RC = list()
PKS_rev = list()
PKS_rev_RC = list()
for i in SeqIO.parse(pksfile, "fasta"): 
    ## forward pks
    match_i = re.search(KS2F, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_for.append(bs)
    ## forward pks, reverse comp
    match_i = re.search(KS2F_RC, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_for_RC.append(bs)
    ## reverse pks primer
    match_i = re.search(KS2R, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_rev.append(bs)
    # reverse pks primer, reverse comp 
    match_i = re.search(KS2R_RC, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_rev_RC.append(bs)


## now write these out as fastas:
org = 'bact'
SeqIO.write(PKS_for, str("PKS_for_"+org+".fa"), "fasta")
SeqIO.write(PKS_for_RC, str("PKS_for_RC_"+org+".fa"), "fasta")
SeqIO.write(PKS_rev, str("PKS_rev_"+org+".fa"), "fasta")
SeqIO.write(PKS_rev_RC, str("PKS_rev_RC_"+org+".fa"), "fasta")

## not finding. 

### grep checks

KS2F=GC.ATGGA.CC.CA.CA..G..T
KS2F_RC=A..C..TG.TG.GG.TCCAT.GC
KS2R=GT.CC.GT.CC.TG..C.TC.AC
KS2R_RC=GT.GA.G..CA.GG.AC.GG.AC
#pksfile='/home/daniel/Documents/job_apps/panama/bigFilesBiodiv/bactPKS.fa'
#pksfile='/home/daniel/Documents/job_apps/panama/bigFilesBiodiv/plantPKS.fa'

grep $KS2F $pksfile | wc -l 
grep $KS2F_RC $pksfile | wc -l 
grep $KS2R $pksfile | wc -l 
grep $KS2R_RC $pksfile | wc -l 

grep $KS2R_RC $pksfile 

## definitely in there
## go back fix the python code

######################### fungi pks #########################

## fungi for pks
pksfile='/home/daniel/Documents/job_apps/panama/bigFilesBiodiv/fungiPKS.fa'
fungiPKShandle = Entrez.esearch(db="nucleotide", 
    term="(((Polyketide Synthase) AND Type I) NOT Type II) NOT Type III AND fungi [ORGN]", 
    idtype="acc",
    retmax=1000,
    usehistory="y",
)

record = Entrez.read(fungiPKShandle)
webenv = record["WebEnv"]
query_key = record["QueryKey"]
fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()

with open(pksfile, 'w') as f:
    f.write(dataNRPS)
    fetch.close()

PKS_for = list()
PKS_for_RC = list()
PKS_rev = list()
PKS_rev_RC = list()
for i in SeqIO.parse(pksfile, "fasta"): 
    ## forward pks
    match_i = re.search(KS2F, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_for.append(bs)
    ## forward pks, reverse comp
    match_i = re.search(KS2F_RC, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_for_RC.append(bs)
    ## reverse pks primer
    match_i = re.search(KS2R, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_rev.append(bs)
    # reverse pks primer, reverse comp 
    match_i = re.search(KS2R_RC, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_rev_RC.append(bs)


## now write these out as fastas:
org = 'fungi'
SeqIO.write(PKS_for, str("PKS_for_"+org+".fa"), "fasta")
SeqIO.write(PKS_for_RC, str("PKS_for_RC_"+org+".fa"), "fasta")
SeqIO.write(PKS_rev, str("PKS_rev_"+org+".fa"), "fasta")
SeqIO.write(PKS_rev_RC, str("PKS_rev_RC_"+org+".fa"), "fasta")

######################### plant pks #########################

## plant for pks

plantPKShandle = Entrez.esearch(db="nucleotide", 
    term="(((Polyketide Synthase) AND Type I) NOT Type II) NOT Type III AND green plants[porgn:__txid33090]", 
    idtype="acc",
    retmax=1000,
    usehistory="y",
)
record = Entrez.read(plantPKShandle)
record['Count']
webenv = record["WebEnv"]
query_key = record["QueryKey"]

fetch = Entrez.efetch(
    db="nucleotide",
    rettype="fasta",
    retmode="text",
    retmax=len(record["IdList"]),
    webenv=webenv,
    query_key=query_key,
    idtype="acc",
)

dataNRPS = fetch.read()

## how many 

pksfile='/home/daniel/Documents/job_apps/panama/bigFilesBiodiv/plantPKS.fa'
with open(pksfile, 'w') as f:
    f.write(dataNRPS)
    fetch.close()

len(record["IdList"])

PKS_for = list()
PKS_for_RC = list()
PKS_rev = list()
PKS_rev_RC = list()
for i in SeqIO.parse(pksfile, "fasta"): 
    ## forward pks
    match_i = re.search(KS2F, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_for.append(bs)
    ## forward pks, reverse comp
    match_i = re.search(KS2F_RC, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_for_RC.append(bs)
    ## reverse pks primer
    match_i = re.search(KS2R, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_rev.append(bs)
    # reverse pks primer, reverse comp 
    match_i = re.search(KS2R_RC, str(i.seq))
    if match_i: 
        bs=Bio.SeqRecord.SeqRecord(
                                Bio.Seq.Seq(match_i.group()),
                                id=i.id,
                                description=i.description,
                                )
        PKS_rev_RC.append(bs)


## now write these out as fastas:

org = 'plant'
SeqIO.write(PKS_for, str("PKS_for_"+org+".fa"), "fasta")
SeqIO.write(PKS_for_RC, str("PKS_for_RC_"+org+".fa"), "fasta")
SeqIO.write(PKS_rev, str("PKS_rev_"+org+".fa"), "fasta")
SeqIO.write(PKS_rev_RC, str("PKS_rev_RC_"+org+".fa"), "fasta")

## how hard is it to to get an aligment of out these?

muscle -in PKS_for_plant.fa  -out PKS_for_plant.afa

muscle -in PKS_for_bact.fa  -out PKS_for_bact.afa

## that was easy, even with ~350 seqs..

## does muscle require correction of reverse compliments?
muscle -in <(cat PKS_for_bact.fa PKS_for_bact_RC.fa) -out testCombo.afa

## looks good.

## can alv show these file formats?
alv testCombo.afa

## neat. will that work in a jupyter notebook?

## not really. let's make some nice graphs in ugene and put them in there
## for now. 

## in the future, I think we need something like:
https://dmnfarrell.github.io/bioinformatics/bokeh-sequence-aligner
 
## anyway...what do we want to show?

## maybe four alignments, NRPS forward and back, PKS forward and back, all organisms

## NRPS is a mess. 

## not sure how to summarize 

## redo bacterial PKS sequences sources, they are almost entirely mycobacterium.

#### ChenDu diagram ####

## let's see if we can get the sequence information for 
## the sequences used to construct the Chen and Du 2015 
## tree for iterative polyketide synthases

## we especially want the AT domains from these. 

## we also want to check non iterative PKSIs 
## too much. But let's see what we can do today.


## to start, can we get their accessions?

## ugh, how do we do this again? use entrez package. 

## let's first just try to get their KS domain sequences

## list of their accession numbers:

aa = pd.read_csv('ChenDuAccessions.csv', header=None)
aa.columns = ['name', 'id','NorP']
accessions=aa.id.to_list()

## we had to update a few accessions numbers
## and in one the sequence data wasn't available: 

## KF954512.1 / WP_011873136.1 "suppressed" by genbank, no nuccore entry, just prot
## <https://www.ncbi.nlm.nih.gov/protein/WP_011873136.1/>

## also, ZP_11383500.1 was not found, changed for nucleotide id KU597647.1, think this is the correct entry


## example from biopython
handle = Entrez.efetch(db="nucleotide", id="AY851612", rettype="gb", retmode="text")
aa = handle.read()

pprint.pprint(aa)

## our data like this? from above:

fetch = Entrez.efetch(
    db="protein",
    rettype="fasta",
    retmode="text",
    id=accessions,
)

## that works, to get the translated protein. But we want the gene sequence...

#look4nuc = Entrez.elink(dbfrom='protein', db='nuccore', id=accessions)

look4nuc = Entrez.elink(dbfrom='protein', db='nucleotide', id="AAD43562.2")

aa = Entrez.read(look4nuc)

## in the case of a single accession, and single result:
idd = aa[0]['LinkSetDb'][0]['Link'][0]['Id']

bb = Entrez.efetch(
    db="nuccore",
    rettype="fasta",
    retmode="text",
    id=idd
)

## can we make a biopython record directly for this?

## Bio.SeqIO has what we need:

record = SeqIO.read( bb, "fasta" )


## okay, so to loop through our accessions and get the fastas we need:

chenDu = pd.read_csv('ChenDuAccessions.csv', header=None)
chenDu.columns = ['name', 'id','NorP','bactOrFungi','nucID']
## our proteins are here:
prots = chenDu[chenDu['NorP'] == 'p'].id.to_list()
## remove problematic protein sequence:
prots.remove('WP_011873136.1')

## get ChenDu nucleotide sequences that are listed by prot accessions:
for i in prots:
    print(i)
    look4nuc = Entrez.elink(dbfrom='protein', db='nucleotide', id=i)
    aa = Entrez.read(look4nuc)
    idd = aa[0]['LinkSetDb'][0]['Link'][0]['Id']
    bb = Entrez.efetch(
        db="nuccore",
        rettype="fasta",
        retmode="text",
        id=idd
    )
    record = SeqIO.read( bb, "fasta" )
    print(i+" is "+ record.id)
    SeqIO.write(record, handle=record.id+'.fa', format='fasta')

## add those nuseq ids to the ChenDu panda

## get the ChenDu accessions that are already nutide seqs:

aa = pd.read_csv('ChenDuAccessions.csv', header=None)
aa.columns = ['name', 'id','NorP']
nucs = aa[aa['NorP'] == 'n'].id.to_list()
for i in nucs:
    print(i)
    bb = Entrez.efetch(
        db="nuccore",
        rettype="fasta",
        retmode="text",
        id=i
    )
    record = SeqIO.read( bb, "fasta" )
    SeqIO.write(record, handle=record.id+'.fa', format='fasta')


## for deleting first mistakes:
#find . -maxdepth 1 -newermt "2020-12-13" -name "*.fa" -exec rm {} \;

#find . -maxdepth 1 -newermt "2020-12-15" -name "*.fa" -exec rm {} \;

## okay, we should have (almost) all the sequences that ChenDu used for
## for their tree of KS homology...can we find our primers in these 
## files?

os.makedirs('./ChenDuAccs')
#find . -maxdepth 1 -newermt "2020-12-13" -name "*.fa" -exec mv '{}' ChenDuAccs/ \;

## how do we search these for the KS regions, where our primers are from?
## or should we just search for our primers...

## primer sequence for KS:

KS2F GCIATGGAYCCICARCARMGIVT
KS2R GTICCIGTICCRTGISCYTCIAC

## this is a good page for this: 
## <https://en.wikipedia.org/wiki/Nucleotide#Abbreviation_codes_for_degenerate_bases>
## 'I' is for inosine, pairs with A, C, or T
## so, I = [TGA]
## not sure, try it.

KS2F = Bio.Seq.Seq("GCIATGGAYCCICARCARMGIVT")

KS2R = Bio.Seq.Seq("GTICCIGTICCRTGISCYTCIAC")

## if we translate this into regex, I think it would look like this:

############################################
##    GC  I  ATGGA Y  CC  I  CA R  CA R   M  G  I   V   T
KS2F="GC[TGA]ATGGA[CT]CC[TGA]CA[AG]CA[AG][AC]G[TGA][ACG]T"
############################################


############################################
## reverse primer
##      GT  I  CC  I  GT  I  CC R  TG  I   S  C Y  TC  I  AC
KS2R = "GT[TGA]CC[TGA]GT[TGA]CC[AG]TG[TGA][CG]C[CT]TC[TGA]AC"
############################################

## to search a sequence:


p = re.compile(KS2F)
aa = "ACAGAGAATGCTCCCCCGCTATGGACCCACAACAGAGAATGCTCCCCCCCCCCCCCCCAGAGAATGCTATGGACCCACAACAGAGAATGCTCCCCCCCCCCCCCCCAGAGAAT"
bb = p.search(aa)
if bb is not None: 
    b, e = p.search(aa).span()
    print('KS2F')
    print(KS2F)
    print(aa[b:e])
else: print ('not found')

p = re.compile(KS2R)
aa = 'GTAGGGGGGGGGGGGGCTTCTACACCTTCTACGTACCGGTGCCGTGGTACCGGTGCCGTGACCTTCTACACCTTCTACGTACCGGTGCCGTGTACCGGTGCCGTGGTACCGGTG'
if bb is not None: 
    b, e = p.search(aa).span()
    print('KS2R')
    print(KS2R)
    print(aa[b:e])
else: print ('not found')

## seems to work. 
## how about reverse complements?

KS2Fseq = Bio.Seq.Seq(KS2F)

str(KS2Fseq.reverse_complement())
## almost works, but brackets...fix manually?

############################################
##       'A]CGT[]TCA[C]GT[]CT[TG]CT[TG]TCA[GG]AG[TCCAT]TCA[GC'
KS2Frc = 'A[CGT][TCA]C[GT][CT]TG[CT]TG[TCA]GG[AG]TCCAT[TCA]GC'
############################################

## check them out:
KS2F
KS2Frc
## looks okay, try a sample search:

'TCCATCGCTGTGGATCTGTGGATCTGTAGTCGCTGTTGTGGATCCATCGCTGTGGATCTGTGGATCTGTGGATCTGTA'

p = re.compile(KS2Frc)
aa = 'TCCATCGCTGTGGATCTGTGGATCTGTAGTCGCTGTTGTGGATCCATCGCTGTGGATCTGTGGATCTGTGGATCTGTA'
bb = p.search(aa)
if bb is not None: 
    b, e = p.search(aa).span()
    print('KS2Frc')
    print(KS2Frc)
    print(aa[b:e])
else: print ('not found')

## okay, get rc of reverse primer

KS2Rseq = Bio.Seq.Seq(KS2R)

str(KS2Rseq.reverse_complement())
## almost works, but brackets...fix manually?

############################################
##       'GT]TCA[GA]AG[G]CG[]TCA[CA]CT[GG]TCA[AC]TCA[GG]TCA[AC'
KS2Rrc = 'GT[TCA]GA[AG]G[CG][TCA]CA[CT]GG[TCA]AC[TCA]GG[TCA]AC'
############################################

## check them out:
KS2R
KS2Rrc
## looks okay, try a sample search:

p = re.compile(KS2Rrc)
aa = 'GAACGGAGTCGAGGCTCACGGTCGAAGGTCATGGCACTGGAACGGCTCACGGAACTGGCACGGAACGGAACGGAACGTCGAAGGTCATGGCACTGGAAC'
#aa = 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG'
bb = p.search(aa)
cc = p.findall(aa)
dd = list(p.finditer(aa))
ee = [ i.span() for i in dd ]

if bb is not None: 
    b, e = p.search(aa).span()
    print('KS2Rrc')
    print(KS2Rrc)
    print(aa[b:e])
else: print ('not found')

## looks okay. 

## to sum up:

### primers and primer RC regexes ###
KS2F="GC[TGA]ATGGA[CT]CC[TGA]CA[AG]CA[AG][AC]G[TGA][ACG]T"
KS2R = "GT[TGA]CC[TGA]GT[TGA]CC[AG]TG[TGA][CG]C[CT]TC[TGA]AC"
KS2Frc = 'A[CGT][TCA]C[GT][CT]TG[CT]TG[TCA]GG[AG]TCCAT[TCA]GC'
KS2Rrc = 'GT[TCA]GA[AG]G[CG][TCA]CA[CT]GG[TCA]AC[TCA]GG[TCA]AC'
### ----------------------------- ###

########################

## can we search our various fastas for these primers? 

KS2Fregex = re.compile(KS2F)
KS2Rregex = re.compile(KS2R)
KS2Frcregex = re.compile(KS2Frc)
KS2Rrcregex = re.compile(KS2Rrc)

hits = []
desc = []
for i in os.listdir('ChenDuAccs'):
    print(i)
    aa = SeqIO.parse(open(('ChenDuAccs/'+i), mode='r'), 'fasta')
    rec = list(aa)[0]
    if KS2Fregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    if KS2Rregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    if KS2Frcregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    if KS2Rrcregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    hits = [ i.replace('.fa', '') for i in hits ]
    hitsU = list(set(hits))


## only 5 non-redundant hits

## any fungal?

hasPrim = chenDu[chenDu['nucID'].isin(hitsU)]

hasPrim.reset_index(inplace=True, drop=True)

hasPrim

## yup, fumonisin gene cluster

## well, maybe we can take align these and take a look at them. 
## how do we get the regions of interest?

## according to the pnas article, we should 
## be looking at amplified regions of 350-500 bp
## does our one sequence with both primers bear this out?

## MonAI 
## AF440781.1

## how do we find the regions we need?


def getPrimerSpan(fafile, primer):
    """use one of the compiled regexes above"""
    with open((fafile), mode='r') as f:
        aa = SeqIO.parse(f, 'fasta')
        sequ = str(list(aa)[0].seq)
    primiter = primer.finditer(sequ)
    if primiter: 
        primerSpans = [ i.span() for i in list(primiter) ]
    else: 
        primerSpans = None
        print('primer not found')
    return(primerSpans)

fafile='ChenDuAccs/AF440781.1.fa'

## forward


getPrimerSpan(fafile=fafile, primer=KS2Fregex)

getPrimerSpan(fafile=fafile, primer=KS2Rregex)

getPrimerSpan(fafile=fafile, primer=KS2Frcregex)

getPrimerSpan(fafile=fafile, primer=KS2Rrcregex)

## these are all very far apart. 


## so what do we need to do? Need to be efficient about time here...

## These are pretty large proteins, average maybe 6,000 AAs. 
## so not going to try to repeat ChenDu's alignment. That is something
## I should get paid to do. 

## and we have to get on to the GIS stuff. can we extract the candidate regions 
## from the primer sites, knowing that they should be maybe 500 bp?

## pipeline for this:

## our fastas with the found primers are:

hasPrimerFiles = [ ("ChenDuAccs/"+i+".fa") for i in hasPrim.nucID.values ]


## in each of these, 
## if they have a forward primer or forward reverse comp, get the next 500 bp
## if they have a reverse or reverse comp, get the previous 500 bp

## try one
KS2Fregex 
KS2Rregex 
KS2Frcregex 
KS2Rrcregex 

hasPrimerFiles[0]

getPrimerSpan(hasPrimerFiles[0],KS2Fregex) ## two hits.
getPrimerSpan(hasPrimerFiles[0],KS2Frcregex) ## no
getPrimerSpan(hasPrimerFiles[0],KS2Rregex) ## three hits.
getPrimerSpan(hasPrimerFiles[0],KS2Rrcregex) ## none. 
## Odd.something may be wrong with our reverse complements

## to get the ~500 bp after each forward hit:

def getBPfromSite(fastafile, site, bp):
    """function to get sequence chunks from before or past a primer site."""
    with open(fastafile, mode='r') as f:
        seqIter = SeqIO.parse(f, 'fasta')
        sequ = list(seqIter)[0].seq
    if bp < 0:
        forfivehundo = sequ[(site[1]+bp):site[1]]
    elif bp > 0:
        forfivehundo = sequ[site[0]:(site[1]+bp)]
    elif bp == 0: 
        forfivehundo = None
    return(forfivehundo)

## okay, this takes one span and gets a sequence from one file

## how do we use this to get our sequences?

## gotta go through all 6 pks sequences, 
##    in each pks, check for presence of each primer
##        in each primer hit, get 500 bp sequence
 
## test with forward primer. so +500 bp

seqName=(hasPrim.nucID.values[i] + '_primer-' +'KS2F')
fastafile=hasPrimerFiles[i]
primer=KS2Fregex

def getSeqsForAPrimer(fastafile, primer, seqName):
    sites = getPrimerSpan(fastafile,primer)
    seqs=[]
    for sitenumber, site in enumerate(sites):
        sequence = getBPfromSite(hasPrimerFiles[0], site=site, bp=500)
        seqid = seqName+'_S'+str(sitenumber)
        seqRec = SeqRecord(sequence) 
        seqRec.id = seqid
        seqs.append(seqRec)
    return(seqs)

getPrimerSpan(fastafile,primer)

primerRegexes=[KS2Fregex, KS2Rregex, KS2Frcregex, KS2Rrcregex]

for i,j in enumerate(
seqName=(hasPrim.nucID.values[i] + '_primer-' +'KS2F')
fastafile=hasPrimerFiles[i]
primer=KS2Fregex
aa = getSeqsForAPrimer(fastafile, primer, seqName)

## write to a fasta file:
SeqIO.write(aa, 'testa.fasta', 'fasta')

## great. so do that for all primers, on all 6 sequences.
## probably reduce the length, to 100 bp?
## otherwise, alignment might be too much.

## back up, prep for jupyter in case this actually works. 
## here are the packages we need to bring in:

import pandas as pd
import shapely as sh
import numpy as np
import os, re, copy
from Bio import Entrez
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.Seq import Seq
Entrez.email = "danchurchthomas@gmail.com"

## and here are the functions we need:

def getPrimerSpan(fafile, primer):
    """use one of the compiled regexes above"""
    with open((fafile), mode='r') as f:
        aa = SeqIO.parse(f, 'fasta')
        sequ = str(list(aa)[0].seq)
    primiter = primer.finditer(sequ)
    if primiter: 
        primerSpans = [ i.span() for i in list(primiter) ]
    else: 
        primerSpans = None
        print('primer not found')
    return(primerSpans)

def getBPfromSite(fastafile, site, bp):
    """function to get sequence chunks from before or past a primer site."""
    with open(fastafile, mode='r') as f:
        seqIter = SeqIO.parse(f, 'fasta')
        sequ = list(seqIter)[0].seq
    if bp < 0:
        seqFrag = sequ[(site[1]+bp):site[1]]
    elif bp > 0:
        seqFrag = sequ[site[0]:(site[1]+bp)]
    elif bp == 0: 
        seqFrag = None
    return(seqFrag)

def getSeqsForAPrimer(fastafile, primer, seqName, seqLength):
    """use getPrimerSpan() and getBPfromSite() to collect the sequence
        fragments from each matching site to a primer and put into a 
        list of biopython sequence record objects"""
    sites = getPrimerSpan(fastafile,primer)
    seqs=[]
    for sitenumber, site in enumerate(sites):
        sequence = getBPfromSite(hasPrimerFiles[0], site=site, bp=seqLength)
        seqid = seqName+'_S'+str(sitenumber)
        seqRec = SeqRecord(sequence) 
        seqRec.id = seqid
        seqs.append(seqRec)
    return(seqs)

## primers and primer RC regexes ##
KS2F="GC[TGA]ATGGA[CT]CC[TGA]CA[AG]CA[AG][AC]G[TGA][ACG]T"
KS2R = "GT[TGA]CC[TGA]GT[TGA]CC[AG]TG[TGA][CG]C[CT]TC[TGA]AC"
KS2Frc = 'A[CGT][TCA]C[GT][CT]TG[CT]TG[TCA]GG[AG]TCCAT[TCA]GC'
KS2Rrc = 'GT[TCA]GA[AG]G[CG][TCA]CA[CT]GG[TCA]AC[TCA]GG[TCA]AC'
## compiled:
KS2Fregex = re.compile(KS2F)
KS2Rregex = re.compile(KS2R)
KS2Frcregex = re.compile(KS2Frc)
KS2Rrcregex = re.compile(KS2Rrc)

## make a series to iterate over
primerRegexes = [KS2Fregex, KS2Rregex, KS2Frcregex, KS2Rrcregex]
primerRegexesNames = ['KS2F', 'KS2R', 'KS2Frc', 'KS2Rrc']
primSeries = pd.Series(primerRegexes, index=primerRegexesNames)

## data
chenDu = pd.read_csv('ChenDuAccessions.csv', header=None)
chenDu.columns = ['name', 'id','NorP','bactOrFungi','nucID']
## our proteins are here:
prots = chenDu[chenDu['NorP'] == 'p'].id.to_list()
## remove problematic protein sequence:
prots.remove('WP_011873136.1')

## find out which of the ChenDu sequences have an exact match
## to our primers:

hits = []
desc = []
for i in os.listdir('ChenDuAccs'):
    print(i)
    aa = SeqIO.parse(open(('ChenDuAccs/'+i), mode='r'), 'fasta')
    rec = list(aa)[0]
    if KS2Fregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    if KS2Rregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    if KS2Frcregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    if KS2Rrcregex.search(str(rec.seq)): hits.append(i); desc.append(rec.description)
    hits = [ i.replace('.fa', '') for i in hits ]
    hitsU = list(set(hits))


hasPrim = chenDu[chenDu['nucID'].isin(hitsU)]
hasPrim.reset_index(inplace=True, drop=True)
hasPrim ## these are our accessions of interest

## our files therefore are:
hasPrimerFiles = [ ("ChenDuAccs/"+i+".fa") for i in hasPrim.nucID.values ]

seqName=(hasPrim.nucID.values[i] + '_primer-' +'KS2F')
fastafile=hasPrimerFiles[i]

primer=KS2Fregex

accessionseqs=[]
for fileNu, file in enumerate(hasPrimerFiles):
    print(file)
    for primNu, prim in enumerate(primSeries):
        seqName=(hasPrim.nucID.values[fileNu] + '_primer-' +primSeries.index[primNu])
        print(seqName)
        if 'F' in primSeries.index[primNu]: n = (+1)
        elif 'R' in primSeries.index[primNu]: n = (-1)
        primHitSeqs=getSeqsForAPrimer(file, primer=prim, seqName=seqName, seqLength=(500*n))
        accessionseqs += primHitSeqs

SeqIO.write(accessionseqs, 'chenDuPrimerHits.fa', 'fasta')

## hmm, hard to do sanity checks on these. guess we gotta do an alignment and 
## see if it makes any sense at all.

## to BASH

muscle -in chenDuPrimerHits.fa -out testAlignChenduHits.fa

alv testAlignChenduHits.fasta

## anyway, looks promising

## that's probably all the time we have for now to deal with the primers.

######## crane site data #######

## okay, gotta start compiling and understanding the data that is available
## from the iDiv folks.

## what have we got?

## we got tree locations, and species id, and DEM, etc, lots of good stuff. 

## what do we do now?

## nail down experimental methods, and sampling scheme. 

## I think I am proposing two projects: functional microbiome survey and transport 
## of fungi.

## a third is hidden in there, doing a basic fungal taxonomic diversity survey, 
## by tucking ITS work in whereever barcoding happens, but downplay this in the
## grant to avoid appearance of over-committing, and making the application too
## complex.

## for the stemflow, basically accompany the proposed stem flow survey with some sterile 
## plants, both subject to stemflow from tree and protected from tree. 

## seedlings will be of one species, the most common or most commonly sampled tree,
## to control for host effects of community assembly. Thus most of the time the 
## seedling species matches host tree, but sometimes doesn't. 

## can we get our tree species into a geojson and into a gpd df?

import copy, os, re
import pandas as pd 
import numpy as np
import geopandas as gpd
import rasterio
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
plt.ion()

lccTrees = gpd.read_file("/home/daniel/Documents/grants/"
                    "geneClust/data/LCCdata/modifiedGISforApp"
                    "/LCCtrees.geojson")


## what are our most common trees?

lccTrees.head()

lccTrees.tail()

lccTrees.spec

lTgroupSpp = lccTrees.groupby(lccTrees.spec)

abundances = lTgroupSpp.agg(np.size)['Tree_ID'].copy()

abundances.sort_values(ascending=False, inplace=True)

abundances.plot.bar()

abundances

"""
BAH = Acer pseudoplatanus
BUL = Ulmus glabra
FAH = Acer campestre
FEUL = Ulmus minor
FLUL = Ulmus laevis
GES= Fraxinus excelsior
HAS = Corylus avellana
HBU= Carpinus betulus
HOL = Sambusus nigra
KPA = Populus canadensius
REI = Quercus rubra
RES = Fraxinus pensylvanica
RKA = Aesculus hippocastanum
RO= Robinia pseudoacacia
SAH= Acer platanoides
SEI= Quercus robur
VKI = Prunus avium
WD = Crataegus sp. 
WLI = Tilia cordata  
"""

## most common types are two non-native maples and tilia.
## what's the goal here? what did Herrmann do in her last paper?

## they did three species, maple, tilia, and oak
## three individuals from each species
## three zones each (lower, mid, upper)
## then three samples from each tree/zone

## 3 x 3 x 3 = 27 samples

## some problems with the sample, spatially clustered - 
## all the oaks at one end, all the lindens at the 
## other, maples distributed between the two clusters.

## so spatial effects alone could have caused their
## putative host effects. 

## have to fix that. 

## to really test host effects, seedlings would be nice. 

lTgroupSpp.agg

help(lTgroupSpp.agg)

## so if I could have all the miseq runs, money, and time I ever wanted,
## what would I sample?

## 1a - match the old sampling, but correct for spatial problem,
## so do a few trees in the middle, match age class and 
## 1b - check for seasonal and yearly effects. 
## 1c - phenology - for 2 years, 2 sampling events per year (beginning and end of year)

## 2 - functional microbiome surveys, 2 years, 2 sampling events
##      - first year without seedlings, also repeat/match bacterial sampling
##      - environmental gradient: seedlings in exposed and sheltered conditions, predicted elevated melanin, anthraquinones, other polyketide pigments:
##      - pertinent secondary metabolites? 

## 3 - stemflow traps - check filters for fungi, also place 

## first year:

## conduct functional study
## grow seedlings
## conduct base level ITS surveys 

## second year:

## seedling studies

## seedings - each site gets 

## 1 open to litter, closed to stem flow (+/-)
## 2 closed to litter, open to stem flow (-/+)
## 3 closed to litter, closed to stem flow (-/-)
## 4 open to litter, open to stem flow  (+/+)

## so let's frame this as a general investigation of the functional 
## microbiome, with an obersvational phase and a experimental phase
## this first phase would also allow the testing of the primers. 

## first year would repeat the methods of Hermann 2020, plus a few 
## trees, but with ITS and candidate PKS/NRPS primers.  Second year 
## would use seedlings, and implement stemflow setup. 

## redo sample diagram to have three zones. 

## make map, with additonal trees. 

## diagram of stem flow experimental setup with seedlings

## first year - 18 samples / tree, 


## anyway, let's make a map of the three species that Herrmann used

lccTrees.head()

## our three species are:

herrmannSpec = ['BAH','SEI','WLI']

## subset to just these:

justHerrmannSpec = lccTrees[lccTrees.spec.isin(herrmannSpec)]

## still huge, about half of our species
justHerrmannSpec.shape

## plot, colored by species.

## get our colors

colorDic = {'BAH':'#f19c43',
            'SEI':'#549ad7',
            'WLI':'#3c7403'}
colsSpec = justHerrmannSpec.spec.apply(lambda x: colorDic[x])

fig, ax = plt.subplots()
justHerrmannSpec.plot(c=colsSpec, ax=ax)

## can we identify the trees used in the original study?:

herrmannTrees = [
                "K129.0",
                "K317.0",
                "K733.0",
                "K33.0" ,
                "K513.1",
                "K754.0",
                "K444.0",
                "K455.0",
                "K517.1"
                ]

herrmannTrees = justHerrmannSpec.Tree_ID.isin(herrmannTrees)

justHerrmannTrees = justHerrmannSpec[herrmannTrees]

colsSpec = justHerrmannTrees.spec.apply(lambda x: colorDic[x])

fig, ax = plt.subplots()
justHerrmannTrees.plot(c=colsSpec, ax=ax)

## well, that looks a little different than their report. 

## less problematic, spatially. I wonder which is correct?

## anyway, doesn't matter. What do we need here? 

## this just in, the Herrmann lab group has decided to drop
## maples, and sample ash instead

## and here is her summary:
## We plan to sample two individuals of three tree species
## each will be equipped with triplicate throughfall samplers at three different height levels (top, mid, bottom position). 
## That will be 9 throughfall samplers per tree. 
## 6 trees x 9 samplers = 54 throughfall samplers total.
## which will give us insight into carbon and nitrogen compounds and microorganisms being transported via throughfall. 
## We were planning to sample six times a year focusing mostly on the vegetation period. 
## Out of these samples, we will select three or four time points a year for in depth community analysis. 
## Each time we sample throughfall, we will also sample leave material nearby the throughfall samplers. 
## Phyllosphere microbial communities will be analyzed for those time points for which we also analyze the communities in the throughfall. 
## We plan to follow this sampling design for two vegetation periods (2021 and 2022). 

## so what am I adding to this?

## ITS sampling to every 16s survey
## seedlings. 

## diagram for network model of leaf collections

## do we have rain data?

wd = ("/home/daniel/Documents/grants/geneClust/data/LCCdata/climateData/")
d4pd = dict()
for h,i in enumerate(os.listdir(wd)):
    print(i)
    aa = pd.read_csv(wd+i)
    bb = aa[['Date','RegenSumme in mm']].copy()
    bb['month'] = [ j[0] for j in bb.Date.str.split("/") ]
    bb.drop(columns='Date', inplace=True)
    cc = bb[['month', 'RegenSumme in mm']].copy()
    yr = re.compile('20[0-9][0-9]')
    yearStr = yr.findall(i)[0]
    print('yearStr = ' + yearStr)
    newnames = list(cc.columns)
    newnames[1] = ('Rain' + yearStr)
    cc.columns = newnames
    dd = pd.Series(cc[('Rain' + yearStr)])
    dd.set_index = cc['month']
    d4pd[('Rain' + yearStr)] = dd 

d4pd['month'] = bb['month']
rainDF = pd.DataFrame(d4pd)
rainDF.set_index('month', inplace=True)
rainDF = rainDF[rainDF.columns.sort_values()]

rainDF.plot()

## that took forever, but the basic message is that there is plenty of summer water 

## great, lots of water, no worries about the stemflow stopping during the summer
